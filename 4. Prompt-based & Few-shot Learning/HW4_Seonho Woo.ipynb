{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86I25vtXqsmo"
   },
   "source": [
    "# Homework 4: Prompt-based NLP\n",
    "### Seonho Woo (clairewo@umich.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uKYA1Q4rlc3P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/clairewo/.local/lib/python3.9/site-packages (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (0.11.0)\n",
      "Requirement already satisfied: filelock in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: requests in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/clairewo/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/clairewo/.local/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clairewo/.local/lib/python3.9/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/clairewo/.local/lib/python3.9/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/clairewo/.local/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clairewo/.local/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fv3DrCYBsh8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate in /home/clairewo/.local/lib/python3.9/site-packages (0.16.0)\n",
      "Requirement already satisfied: pyyaml in /home/clairewo/.local/lib/python3.9/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: psutil in /home/clairewo/.local/lib/python3.9/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/clairewo/.local/lib/python3.9/site-packages (from accelerate) (1.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from accelerate) (21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/clairewo/.local/lib/python3.9/site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/clairewo/.local/lib/python3.9/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/clairewo/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/clairewo/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/clairewo/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/clairewo/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/clairewo/.local/lib/python3.9/site-packages (from torch>=1.4.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate) (58.0.4)\n",
      "Requirement already satisfied: wheel in /home/clairewo/.local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate) (0.40.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xt2wirNTHWxb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openprompt in /home/clairewo/.local/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: rouge==1.0.0 in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (1.0.0)\n",
      "Requirement already satisfied: yacs in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (0.1.8)\n",
      "Requirement already satisfied: datasets in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (2.11.0)\n",
      "Requirement already satisfied: tqdm>=4.62.2 in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (4.64.1)\n",
      "Requirement already satisfied: pyarrow in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (11.0.0)\n",
      "Requirement already satisfied: nltk in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (3.7)\n",
      "Requirement already satisfied: sentencepiece==0.1.96 in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (0.1.96)\n",
      "Requirement already satisfied: dill in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (0.3.6)\n",
      "Requirement already satisfied: scipy in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (1.9.1)\n",
      "Requirement already satisfied: transformers>=4.10.0 in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (4.24.0)\n",
      "Requirement already satisfied: tensorboardX in /home/clairewo/.local/lib/python3.9/site-packages (from openprompt) (2.6)\n",
      "Requirement already satisfied: six in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from rouge==1.0.0->openprompt) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/clairewo/.local/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (3.8.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (2022.10.31)\n",
      "Requirement already satisfied: requests in /home/clairewo/.local/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/clairewo/.local/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from transformers>=4.10.0->openprompt) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/clairewo/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.10.0->openprompt) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/clairewo/.local/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.10.0->openprompt) (3.0.9)\n",
      "Requirement already satisfied: pandas in /home/clairewo/.local/lib/python3.9/site-packages (from datasets->openprompt) (1.5.1)\n",
      "Requirement already satisfied: aiohttp in /home/clairewo/.local/lib/python3.9/site-packages (from datasets->openprompt) (3.8.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/clairewo/.local/lib/python3.9/site-packages (from datasets->openprompt) (2023.4.0)\n",
      "Requirement already satisfied: xxhash in /home/clairewo/.local/lib/python3.9/site-packages (from datasets->openprompt) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/clairewo/.local/lib/python3.9/site-packages (from datasets->openprompt) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /home/clairewo/.local/lib/python3.9/site-packages (from datasets->openprompt) (0.70.14)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets->openprompt) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets->openprompt) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets->openprompt) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from aiohttp->datasets->openprompt) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets->openprompt) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets->openprompt) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets->openprompt) (1.3.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/clairewo/.local/lib/python3.9/site-packages (from requests->transformers>=4.10.0->openprompt) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clairewo/.local/lib/python3.9/site-packages (from requests->transformers>=4.10.0->openprompt) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clairewo/.local/lib/python3.9/site-packages (from requests->transformers>=4.10.0->openprompt) (2022.9.24)\n",
      "Requirement already satisfied: click in /home/clairewo/.local/lib/python3.9/site-packages (from nltk->openprompt) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/clairewo/.local/lib/python3.9/site-packages (from nltk->openprompt) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/clairewo/.local/lib/python3.9/site-packages (from pandas->datasets->openprompt) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/clairewo/.local/lib/python3.9/site-packages (from pandas->datasets->openprompt) (2.8.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorboardX->openprompt) (3.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openprompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "poDzvbPRsZ7p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in /home/clairewo/.local/lib/python3.9/site-packages (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (1.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (0.11.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (4.64.1)\n",
      "Requirement already satisfied: packaging in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from evaluate) (21.0)\n",
      "Requirement already satisfied: xxhash in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: responses<0.19 in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: dill in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (2.11.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (2.28.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/clairewo/.local/lib/python3.9/site-packages (from evaluate) (2023.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/clairewo/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in /home/clairewo/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/clairewo/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/clairewo/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: filelock in /home/clairewo/.local/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/clairewo/.local/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/clairewo/.local/lib/python3.9/site-packages (from packaging->evaluate) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clairewo/.local/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clairewo/.local/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/clairewo/.local/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/clairewo/.local/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/clairewo/.local/lib/python3.9/site-packages (from pandas->evaluate) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/clairewo/.local/lib/python3.9/site-packages (2.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (23.3.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (1.53.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (0.4.8)\n",
      "Requirement already satisfied: packaging in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (2.12.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/clairewo/.local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in /home/clairewo/.local/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/clairewo/.local/lib/python3.9/site-packages (from jax>=0.3.15->tensorflow) (1.9.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/clairewo/.local/lib/python3.9/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/clairewo/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/clairewo/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/clairewo/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/clairewo/.local/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/clairewo/.local/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/clairewo/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/clairewo/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/clairewo/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clairewo/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clairewo/.local/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/clairewo/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/clairewo/.local/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0YasXFd4aFKj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "from collections import Counter, defaultdict\n",
    "#import datasets\n",
    "#from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/clairewo/.local/lib/python3.9/site-packages (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/clairewo/.local/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/clairewo/.local/lib/python3.9/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/clairewo/.local/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/clairewo/.local/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/clairewo/.local/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /home/clairewo/.local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (58.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jkYLb3goas8u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 09:13:08.952148: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-26 09:13:10.222361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 09:13:16.539357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "#from sklearn.dummy import DummyClassifier\n",
    "#from datasets import load_dataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnPbJOYtrNfJ"
   },
   "source": [
    "## **Prompt-based Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TRND7_Hq-6C"
   },
   "source": [
    "## Problem 1. \n",
    "(10 points) Write a simple piece code that takes a single word as input and then\n",
    "tokenizes it with the BERT tokenizer in huggingface and returns the word’s corresponding tokens (or token IDs) in the BERT vocabulary. You’ll want to use this piece of code in the next task to check that your verbalizer is using only single-token words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EGS5wUG-SQQ4"
   },
   "outputs": [],
   "source": [
    "# Tokenize train and evaluation datasets with BertTokenizer\n",
    "from transformers import BertTokenizer\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Et3w5wLbaer",
    "outputId": "da65563c-8794-4a89-d42b-9f50c5feb958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a single word:  tokenizing\n"
     ]
    }
   ],
   "source": [
    "entry = input(\"Enter a single word: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2HmXThytcDAZ",
    "outputId": "1ff0a0a7-c5ff-4ac0-bb5a-9292fcd60de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tokenizing'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4X6_Cziq07x"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "def tokenize_word(word):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    return tokens, token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Re0fmK3Wxk6j",
    "outputId": "dd3a1dce-e6f2-4af7-d7e0-6ef31f1b3955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['token', '##izing'] [19204, 6026]\n"
     ]
    }
   ],
   "source": [
    "tokens, token_ids = tokenize_word(entry)\n",
    "print(tokens, token_ids)\n",
    "#tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Few-shot Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMCAccvQrHWv"
   },
   "source": [
    "## Problem 2. \n",
    "(20 points) Write 10 different prompts that can be used to classify toxic speech. Prompts should be relatively different (not just adding/changing one word). For each, come up with at least 2 verbalizations of each class (toxic/non-toxic). You can share verbalizations across prompts if needed. We really want to see some creativity across your prompts (this will also help the model learn more too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openprompt.prompts import ManualTemplate\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "from openprompt.data_utils import InputExample\n",
    "from openprompt.plms import load_plm\n",
    "from openprompt import PromptForClassification, PromptDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "plm_object = load_plm(\"bert\", \"microsoft/MiniLM-L12-H384-uncased\")\n",
    "tokenizer = plm_object[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"toxic\", \"nontoxic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template_1 = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"}. Were there swear words in the previous sentence? {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_1 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"yes\"],\n",
    "        \"nontoxic\": [\"no\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_2 = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"}. On a scale of 1-5, how rude was that sentence? {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_2 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"4\", \"5\"],\n",
    "        \"nontoxic\": [\"1\", \"2\", \"3\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_3 = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"}. What was the author of the previous sentence feeling? {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_3 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"anger\", \"frustration\", \"sad\", \"depressed\"],\n",
    "        \"nontoxic\": [\"content\", \"happy\", \"calm\", \"nothing\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_4 = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"}. Would you kiss your mother with that mouth? {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_4 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"no\"],\n",
    "        \"nontoxic\": [\"yes\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_5 = ManualTemplate(\n",
    "    text = '{\"placeholder\":\"text_a\"}. If that sentence were spoken out, how loud would it be on a scale of 1-5? {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "prompt_verbalizer_5 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"4\", \"5\"],\n",
    "        \"nontoxic\": [\"1\", \"2\", \"3\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_6 = ManualTemplate(\n",
    "    text = 'Alice: How are you? Bob: {\"placeholder\":\"text_a\"}. Alice: That\\'s {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "prompt_verbalizer_6 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"rude\", \"terrible\", \"bad\"],\n",
    "        \"nontoxic\": [\"nice\", \"good\", \"alright\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_7 = ManualTemplate(\n",
    "    text = 'If someone said {\"placeholder\":\"text_a\"} that would be {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_7 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"rude\", \"terrible\", \"bad\"],\n",
    "        \"nontoxic\": [\"nice\", \"good\", \"alright\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_8 = ManualTemplate(\n",
    "    text = 'If I agree with {\"placeholder\":\"text_a\"} then I am {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_8 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"rude\", \"terrible\", \"dick\", \"horrible\"],\n",
    "        \"nontoxic\": [\"nice\", \"good\", \"alright\", \"calm\", \"composed\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_9 = ManualTemplate(\n",
    "    text = '''\n",
    "    YOU GAY ASSHOLE MOTHERFUCKER, THAT'S BULLSHIT. Is this toxic? yes\n",
    "    Well, that's alright, you didn't know. Is this toxic? no\n",
    "    {\"placeholder\":\"text_a\"}. Is this toxic? {\"mask\"}\n",
    "    ''',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_9 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"yes\"],\n",
    "        \"nontoxic\": [\"no\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_template_10 = ManualTemplate(\n",
    "    text = 'As a Reddit mod would you ban this comment: {\"placeholder\":\"text_a\"}? {\"mask\"}',\n",
    "    tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "prompt_verbalizer_10 = ManualVerbalizer(\n",
    "    classes = classes,\n",
    "    label_words = {\n",
    "        \"toxic\": [\"yes\"],\n",
    "        \"nontoxic\": [\"no\"],\n",
    "    },\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixSH-W0ZqqN4"
   },
   "outputs": [],
   "source": [
    "# prompt1 = \"What do you think of people who engage in this behavior?\"\n",
    "# prompt2 = \"What is your opinion on using derogatory terms?\"\n",
    "# prompt3 = \"Do you believe in equal rights for all people, regardless of their identity?\"\n",
    "# prompt4 = \"How would you react to someone with a different opinion than yours?\"\n",
    "# prompt5 = \"What is your stance on cyberbullying?\"\n",
    "# prompt6 = \"What are your thoughts on using violence to solve conflicts?\"\n",
    "# prompt7 = \"How do you feel about people who are different from you?\"\n",
    "# prompt8 = \"What is your opinion on making offensive jokes?\"\n",
    "# prompt9 = \"What is your opinion on making offensive jokes?\"\n",
    "# prompt10 = \"What is your opinion on making offensive jokes?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptClassifier:\n",
    "    def __init__(self, template, verbalizer, plm_obj):\n",
    "        self.plm, self.tokenizer, self.model_config, self.WrapperClass = plm_obj\n",
    "        self.template = template\n",
    "        self.verbalizer = verbalizer\n",
    "        self.model = PromptForClassification(\n",
    "            template = template,\n",
    "            plm = self.plm,\n",
    "            verbalizer = verbalizer,\n",
    "        )\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        self.optim = AdamW(self.model.parameters(), lr=1e-2)\n",
    "    \n",
    "    def create_data_loader(self, dataset):\n",
    "        return PromptDataLoader(\n",
    "            dataset = dataset,\n",
    "            tokenizer = self.tokenizer,\n",
    "            template = self.template,\n",
    "            tokenizer_wrapper_class = self.WrapperClass,\n",
    "        )\n",
    "\n",
    "    def train(self, dataset):\n",
    "        for batch in tqdm(self.create_data_loader(dataset)):\n",
    "            logits = self.model(batch)\n",
    "            preds = torch.argmax(logits, dim = -1)\n",
    "            loss = self.criterion(preds.float(), batch[\"label\"].float())\n",
    "            loss = torch.autograd.Variable(loss, requires_grad = True)\n",
    "            self.optim.step()\n",
    "            self.optim.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "    def evaluate(self, eval_dataset):\n",
    "        self.model.eval()\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.create_data_loader(eval_dataset)):\n",
    "                logits = self.model(batch)\n",
    "                preds = torch.argmax(logits, dim = -1)\n",
    "                y_pred.append(preds.item())\n",
    "                y_true.append(batch[\"label\"].item())    \n",
    "        return f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"jigsaw-train.csv\")\n",
    "eval_df = pd.read_csv(\"jigsaw-dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PromptClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2607309/1925725502.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mfs_f1_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mprompt_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPromptClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prompt_template_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prompt_verbalizer_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplm_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprompt_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mfsclassifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PromptClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "fewshot_classifiers = []\n",
    "for i in tqdm(range(10)):\n",
    "    train_dataset_0 = [\n",
    "        InputExample(\n",
    "            guid=idx,\n",
    "            text_a=row[\"comment_text\"],\n",
    "            label=row[\"toxic\"]\n",
    "        ) for idx, row in train_df[train_df[\"toxic\"] == 0].sample(5).iterrows()\n",
    "    ]\n",
    "\n",
    "    train_dataset_1 = [\n",
    "        InputExample(\n",
    "            guid=idx,\n",
    "            text_a=row[\"comment_text\"],\n",
    "            label=row[\"toxic\"]\n",
    "        ) for idx, row in train_df[train_df[\"toxic\"] == 1].sample(5).iterrows()\n",
    "    ]\n",
    "\n",
    "    train_dataset = train_dataset_0 + train_dataset_1\n",
    "\n",
    "    eval_dataset_0 = [\n",
    "        InputExample(\n",
    "            guid=idx,\n",
    "            text_a=row[\"comment_text\"],\n",
    "            label=row[\"toxic\"]\n",
    "        ) for idx, row in eval_df[eval_df[\"toxic\"] == 0].sample(5).iterrows()\n",
    "    ]\n",
    "\n",
    "    eval_dataset_1 = [\n",
    "        InputExample(\n",
    "            guid=idx,\n",
    "            text_a=row[\"comment_text\"],\n",
    "            label=row[\"toxic\"]\n",
    "        ) for idx, row in eval_df[eval_df[\"toxic\"] == 1].sample(5).iterrows()\n",
    "    ]\n",
    "\n",
    "    eval_dataset = eval_dataset_0 + eval_dataset_1\n",
    "    \n",
    "    fsclassifiers = []\n",
    "    fs_f1_scores = []\n",
    "    for i in range(1, 11):\n",
    "        prompt_classifier = PromptClassifier(eval(\"prompt_template_\" + str(i)), eval(\"prompt_verbalizer_\" + str(i)), plm_object)\n",
    "        prompt_classifier.train(train_dataset)\n",
    "        fsclassifiers.append(prompt_classifier)\n",
    "        score = prompt_classifier.evaluate(eval_dataset)\n",
    "        fs_f1_scores.append(score)\n",
    "    fewshot_classifiers.append(np.argmax(fs_f1_scores))\n",
    "    \n",
    "fewshot_model_idx = max(set(fewshot_classifiers), key=fewshot_classifiers.count)\n",
    "fewshot_model = fsclassifiers[fewshot_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_model_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " [0.5,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.4000000000000001,\n",
       "  0.5714285714285714])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_model_idx, fs_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW-kOmnYrRf1"
   },
   "source": [
    "## **Zero-shot Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8GdOCbVrVm3"
   },
   "source": [
    "## Problem 3. \n",
    "(20 points) Write 10 different zero-shot prompts that can be used to classify toxic speech. Prompts should be relatively different (not just adding/changing one word). We want you to try exploring the space of how to create a prompt. Some of the questions above can be used for inspiration, but there is a lot of room to explore here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding, AutoTokenizer, AutoModelForSequenceClassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroShotClassifier:\n",
    "    def __init__(self, template, verbalizer, tokenizer, model):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.template = template\n",
    "        self.verbalizer = verbalizer\n",
    "        self.model = model\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "\n",
    "    def evaluate(self, eval_dataset, eval=True):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        with torch.no_grad():\n",
    "            for idx, row in tqdm(eval_dataset.iterrows()):\n",
    "                input = self.template.format(row[\"comment_text\"])\n",
    "                input = self.tokenizer(input, return_tensors=\"pt\")\n",
    "                output = self.model.generate(**input, temperature=0.8, max_new_tokens=500)\n",
    "                output = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "                Flag = False\n",
    "                for verb in self.verbalizer:\n",
    "                    if not Flag:\n",
    "                        for label in self.verbalizer[verb]:\n",
    "                            if label in output[0].lower():\n",
    "                                y_pred.append(verb)\n",
    "                                Flag = True\n",
    "                                break\n",
    "                if not Flag:\n",
    "                    y_pred.append(\"nontoxic\") # guess most frequent class if no answer is available\n",
    "                if eval:\n",
    "                    y_true.append(row[\"toxic\"])\n",
    "        y_pred = list(map(lambda yi: 1 if yi == \"toxic\" else 0, y_pred))\n",
    "        return [y_pred, f1_score(y_true, y_pred) if eval else None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "7PXsUrLYcJ8K",
    "outputId": "6a770901-e73a-4320-f6d1-eada606ec7d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbalizer1 = {\"toxic\": [\"yes\"], \"nontoxic\": [\"no\"]}\n",
    "prompt1 = \"\"\"\n",
    "Text: I disagree with your opinion, but I respect your right to hold it.\n",
    "Label: no\n",
    "Text: You're an idiot for thinking that way.\n",
    "Label: yes\n",
    "Text: {}\n",
    "Label:\n",
    "\"\"\"\n",
    "\n",
    "verbalizer2 = {\"toxic\": [\"yes\"], \"nontoxic\": [\"no\"]}\n",
    "prompt2 = \"\"\"\n",
    "Below is an example of a instagram comment:\n",
    "\n",
    "{}\n",
    "\n",
    "If this comment is being rude or contains bullying words, reply yes. Otherwise, type no.\n",
    "\"\"\"\n",
    "\n",
    "verbalizer3 = {\"toxic\": [\"A\"], \"nontoxic\": [\"B\"]}\n",
    "prompt3 = \"\"\"\n",
    "There are two people A and B who is each being toxic and nontoxic.\n",
    "\n",
    "A. \"I'm sorry, but I have to disagree with you.\"\n",
    "B. \"You're wrong and you should be ashamed of yourself.\"\n",
    "\n",
    "{}\n",
    "Who would say this? 'A' or 'B'?\n",
    "\"\"\"\n",
    "\n",
    "verbalizer4 = {\"toxic\": [\"A\"], \"nontoxic\": [\"B\"]}\n",
    "prompt4 = \"\"\"\n",
    "Text: I understand where you're coming from, but I don't agree with your perspective.\n",
    "Label: no\n",
    "Text: You're a terrible person for thinking that way.\n",
    "Label: yes\n",
    "Text: {}\n",
    "Label:\n",
    "\"\"\"\n",
    "\n",
    "verbalizer5 = {\"toxic\": [str(i) for i in range(5)], \"nontoxic\": [str(i) for i in range(6, 11)]}\n",
    "prompt5 = \"\"\"\n",
    "How was this restaurant's dishes taste? Rate them with the score between 0 to 10.\n",
    "\n",
    "{}\n",
    "Answer with a score between 0 to 10.\n",
    "\"\"\"\n",
    "\n",
    "verbalizer6 = {\"toxic\": [str(i) for i in range(15)], \"nontoxic\": [str(i) for i in range(15, 100)]}\n",
    "prompt6 =  \"\"\"\n",
    "If your server said this, how much would you like to tip them between 0 and 20%:\n",
    "\n",
    "{}\n",
    "\n",
    "Type a number between 0 and 20 that you will tip him.\n",
    "\"\"\"\n",
    "\n",
    "verbalizer7 = {\"toxic\": [\"yes\"], \"nontoxic\": [\"no\"]}\n",
    "prompt7 = \"\"\"\n",
    "If it has uppercase words, it is toxic.\n",
    "If it has the words 'fuck', 'asshole', 'dick', it is toxic.\n",
    "\n",
    "Here is an example:\n",
    "\n",
    "{}\n",
    "\n",
    "Reply with yes or no. Is it toxic?\n",
    "\"\"\"\n",
    "\n",
    "verbalizer8 = {\"toxic\": [\"yes\"], \"nontoxic\": [\"no\"]}\n",
    "prompt8 =  \"\"\"\n",
    "Text: I respect your opinion, but I have to disagree with it.\n",
    "Label: no\n",
    "Text: You're a horrible person for having that opinion.\n",
    "Label: yes\n",
    "Text: {}\n",
    "Label:\n",
    "\"\"\"\n",
    "\n",
    "verbalizer9 = {\"toxic\": [\"yes\"], \"nontoxic\": [\"no\"]}\n",
    "prompt9 = \"\"\"\n",
    "Justin is a polite guy who does not curse.\n",
    "Evelyn is arude, obnoxious girl who says mean things.\n",
    "\n",
    "Who said the following:\n",
    "{}\n",
    "If Justin, say no and if Evelyn, say yes.\n",
    "\"\"\"\n",
    "\n",
    "verbalizer10 = {\"toxic\": [\"A\"], \"nontoxic\": [\"B\"]}\n",
    "prompt10 = \"\"\"\n",
    "A: \"It's hilarious that people can't handle bullying.\"\n",
    "B: \"Cyberbullying is cruel. It's never okay.\"\n",
    "\n",
    "Who said the following?\n",
    "{}\n",
    "A or B?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdrive\n",
    "# datapath = \"drive/My Drive/SI 630/HW/Homework 4/\"\n",
    "# train_df = pd.read_csv(datapath + \"jigsaw-train.csv\")\n",
    "# test_df = pd.read_csv(datapath + \"jigsaw-test.csv\")\n",
    "# eval_df = pd.read_csv(datapath + \"jigsaw-dev.csv\")\n",
    "\n",
    "train_df = pd.read_csv(\"jigsaw-train.csv\")\n",
    "test_df = pd.read_csv(\"jigsaw-test.csv\")\n",
    "eval_df = pd.read_csv(\"jigsaw-dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d9836e25d089cab8</td>\n",
       "      <td>I suggest you add this to the LARPA wiki inste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3fbed19498484f71</td>\n",
       "      <td>, 19 May 2008 (UTC) \\n ::The AFD is truly sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>be887f0617e43898</td>\n",
       "      <td>===Train name, misnomer=== \\n The problem is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ddb1781c5174e079</td>\n",
       "      <td>March 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f04966e1d4d2b61</td>\n",
       "      <td>unfair warnings as threats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32004</th>\n",
       "      <td>22abb35000de7828</td>\n",
       "      <td>== Motion Picture Association of America film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32005</th>\n",
       "      <td>834fd790ecbcf68f</td>\n",
       "      <td>\" \\n\\n ==WikiProject Pharmacology Update== \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32006</th>\n",
       "      <td>76417c0f552a71b2</td>\n",
       "      <td>That's nonsense. Most lists of Jews explicitly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32007</th>\n",
       "      <td>6c7c337a97b1d905</td>\n",
       "      <td>==References== \\n Removed Youtube link to V-En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32008</th>\n",
       "      <td>b287221057d59bb9</td>\n",
       "      <td>\" \\n ::Yeah, I know the research is still ongo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text\n",
       "0      d9836e25d089cab8  I suggest you add this to the LARPA wiki inste...\n",
       "1      3fbed19498484f71  , 19 May 2008 (UTC) \\n ::The AFD is truly sad ...\n",
       "2      be887f0617e43898  ===Train name, misnomer=== \\n The problem is t...\n",
       "3      ddb1781c5174e079                                         March 2006\n",
       "4      6f04966e1d4d2b61                         unfair warnings as threats\n",
       "...                 ...                                                ...\n",
       "32004  22abb35000de7828  == Motion Picture Association of America film ...\n",
       "32005  834fd790ecbcf68f  \" \\n\\n ==WikiProject Pharmacology Update== \\n ...\n",
       "32006  76417c0f552a71b2  That's nonsense. Most lists of Jews explicitly...\n",
       "32007  6c7c337a97b1d905  ==References== \\n Removed Youtube link to V-En...\n",
       "32008  b287221057d59bb9  \" \\n ::Yeah, I know the research is still ongo...\n",
       "\n",
       "[32009 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:02,  2.27s/it]\u001b[A\n",
      "2it [00:02,  1.10s/it]\u001b[A\n",
      "5it [00:02,  2.85it/s]\u001b[A\n",
      "7it [00:02,  4.30it/s]\u001b[A\n",
      "10it [00:03,  3.21it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  4.28it/s]\u001b[A\n",
      "2it [00:00,  3.32it/s]\u001b[A\n",
      "3it [00:00,  3.86it/s]\u001b[A\n",
      "4it [00:00,  4.56it/s]\u001b[A\n",
      "6it [00:08,  1.98s/it]\u001b[A\n",
      "10it [00:08,  1.20it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 15.77it/s]\u001b[A\n",
      "4it [00:00, 17.86it/s]\u001b[A\n",
      "6it [00:00, 17.85it/s]\u001b[A\n",
      "8it [00:00, 14.91it/s]\u001b[A\n",
      "10it [00:00, 16.25it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 18.77it/s]\u001b[A\n",
      "5it [00:00, 20.39it/s]\u001b[A\n",
      "8it [00:00, 16.60it/s]\u001b[A\n",
      "10it [00:00, 17.60it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 15.50it/s]\u001b[A\n",
      "4it [00:00,  9.08it/s]\u001b[A\n",
      "6it [00:00, 10.03it/s]\u001b[A\n",
      "10it [00:00, 11.07it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 15.41it/s]\u001b[A\n",
      "4it [00:00, 15.91it/s]\u001b[A\n",
      "6it [00:00, 14.39it/s]\u001b[A\n",
      "8it [00:00, 11.87it/s]\u001b[A\n",
      "10it [00:00, 13.04it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 16.21it/s]\u001b[A\n",
      "4it [00:00, 17.08it/s]\u001b[A\n",
      "6it [00:00, 16.96it/s]\u001b[A\n",
      "8it [00:00, 14.20it/s]\u001b[A\n",
      "10it [00:00, 15.41it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 16.63it/s]\u001b[A\n",
      "5it [00:00, 18.65it/s]\u001b[A\n",
      "7it [00:00, 17.70it/s]\u001b[A\n",
      "10it [00:00, 16.01it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 13.50it/s]\u001b[A\n",
      "4it [00:00, 16.14it/s]\u001b[A\n",
      "6it [00:08,  1.94s/it]\u001b[A\n",
      "8it [00:08,  1.23s/it]\u001b[A\n",
      "10it [00:08,  1.11it/s]\u001b[A\n",
      " 10%|█         | 1/10 [00:24<03:41, 24.57s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.82it/s]\u001b[A\n",
      "6it [00:00, 20.68it/s]\u001b[A\n",
      "10it [00:00, 18.85it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  7.11it/s]\u001b[A\n",
      "4it [00:00, 15.83it/s]\u001b[A\n",
      "7it [00:00, 11.92it/s]\u001b[A\n",
      "10it [00:07,  1.27it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 16.31it/s]\u001b[A\n",
      "4it [00:00, 16.73it/s]\u001b[A\n",
      "6it [00:00, 17.24it/s]\u001b[A\n",
      "8it [00:00, 15.59it/s]\u001b[A\n",
      "10it [00:00, 16.22it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.89it/s]\u001b[A\n",
      "6it [00:00, 19.14it/s]\u001b[A\n",
      "8it [00:00, 17.03it/s]\u001b[A\n",
      "10it [00:00, 17.66it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.10it/s]\u001b[A\n",
      "4it [00:00,  6.68it/s]\u001b[A\n",
      "5it [00:00,  5.27it/s]\u001b[A\n",
      "6it [00:01,  2.15it/s]\u001b[A\n",
      "8it [00:02,  3.47it/s]\u001b[A\n",
      "10it [00:09,  1.08it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 13.31it/s]\u001b[A\n",
      "4it [00:00, 15.08it/s]\u001b[A\n",
      "6it [00:00, 15.37it/s]\u001b[A\n",
      "8it [00:00, 14.01it/s]\u001b[A\n",
      "10it [00:00, 14.40it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.99it/s]\u001b[A\n",
      "6it [00:00, 19.61it/s]\u001b[A\n",
      "8it [00:00, 17.23it/s]\u001b[A\n",
      "10it [00:00, 18.02it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.16it/s]\u001b[A\n",
      "4it [00:00, 18.75it/s]\u001b[A\n",
      "6it [00:00, 18.03it/s]\u001b[A\n",
      "8it [00:00, 15.78it/s]\u001b[A\n",
      "10it [00:00, 16.51it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.16it/s]\u001b[A\n",
      "6it [00:00, 20.09it/s]\u001b[A\n",
      "10it [00:07,  1.32it/s][A\n",
      " 20%|██        | 2/10 [00:52<03:34, 26.78s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.46it/s]\u001b[A\n",
      "4it [00:00, 17.94it/s]\u001b[A\n",
      "6it [00:00, 18.72it/s]\u001b[A\n",
      "8it [00:00, 18.48it/s]\u001b[AToken indices sequence length is longer than the specified maximum sequence length for this model (1298 > 512). Running this sequence through the model will result in indexing errors\n",
      "\n",
      "10it [00:01,  9.58it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  5.56it/s]\u001b[A\n",
      "3it [00:00,  8.06it/s]\u001b[A\n",
      "4it [00:00,  4.97it/s]\u001b[A\n",
      "5it [00:00,  5.41it/s]\u001b[A\n",
      "8it [00:01,  9.48it/s]\u001b[A\n",
      "10it [00:01,  5.06it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.15it/s]\u001b[A\n",
      "4it [00:00, 17.69it/s]\u001b[A\n",
      "7it [00:00, 18.83it/s]\u001b[A\n",
      "10it [00:01,  9.66it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 18.78it/s]\u001b[A\n",
      "4it [00:00, 18.85it/s]\u001b[A\n",
      "7it [00:00, 19.66it/s]\u001b[A\n",
      "10it [00:01,  9.65it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.88it/s]\u001b[A\n",
      "3it [00:00,  5.33it/s]\u001b[A\n",
      "4it [00:00,  6.14it/s]\u001b[A\n",
      "6it [00:01,  5.57it/s]\u001b[A\n",
      "7it [00:01,  3.63it/s]\u001b[A\n",
      "9it [00:01,  5.53it/s]\u001b[A\n",
      "10it [00:02,  4.10it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.45it/s]\u001b[A\n",
      "3it [00:01,  2.05it/s]\u001b[A\n",
      "5it [00:01,  3.72it/s]\u001b[A\n",
      "7it [00:01,  5.53it/s]\u001b[A\n",
      "10it [00:02,  4.02it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 15.22it/s]\u001b[A\n",
      "4it [00:00, 15.56it/s]\u001b[A\n",
      "6it [00:00, 16.57it/s]\u001b[A\n",
      "8it [00:00, 16.34it/s]\u001b[A\n",
      "10it [00:01,  8.94it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 16.76it/s]\u001b[A\n",
      "4it [00:00, 17.94it/s]\u001b[A\n",
      "7it [00:00, 19.48it/s]\u001b[A\n",
      "10it [00:00, 10.03it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.47it/s]\u001b[A\n",
      "3it [00:00,  4.64it/s]\u001b[A\n",
      "5it [00:00,  7.62it/s]\u001b[A\n",
      "8it [00:01, 10.99it/s]\u001b[A\n",
      "10it [00:01,  5.46it/s]\u001b[A\n",
      " 30%|███       | 3/10 [01:06<02:26, 20.95s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.44it/s]\u001b[A\n",
      "3it [00:00,  9.24it/s]\u001b[A\n",
      "5it [00:00, 12.26it/s]\u001b[A\n",
      "7it [00:00, 14.17it/s]\u001b[A\n",
      "10it [00:00, 11.68it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.67it/s]\u001b[A\n",
      "2it [00:00,  7.22it/s]\u001b[A\n",
      "3it [00:00,  4.85it/s]\u001b[A\n",
      "6it [00:00,  9.86it/s]\u001b[A\n",
      "8it [00:01,  5.97it/s]\u001b[A\n",
      "10it [00:01,  6.78it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.13it/s]\u001b[A\n",
      "3it [00:00,  9.34it/s]\u001b[A\n",
      "5it [00:00, 12.76it/s]\u001b[A\n",
      "7it [00:00, 15.03it/s]\u001b[A\n",
      "10it [00:00, 11.75it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 13.88it/s]\u001b[A\n",
      "4it [00:00, 11.05it/s]\u001b[A\n",
      "7it [00:00, 14.98it/s]\u001b[A\n",
      "10it [00:00, 12.76it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.87it/s]\u001b[A\n",
      "3it [00:00,  5.63it/s]\u001b[A\n",
      "5it [00:00,  4.83it/s]\u001b[A\n",
      "7it [00:01,  7.04it/s]\u001b[A\n",
      "10it [00:01,  6.36it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.31it/s]\u001b[A\n",
      "3it [00:01,  1.78it/s]\u001b[A\n",
      "5it [00:02,  2.04it/s]\u001b[A\n",
      "7it [00:02,  3.25it/s]\u001b[A\n",
      "10it [00:02,  3.55it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00, 10.00it/s]\u001b[A\n",
      "3it [00:00,  9.76it/s]\u001b[A\n",
      "5it [00:00, 13.14it/s]\u001b[A\n",
      "7it [00:00, 15.36it/s]\u001b[A\n",
      "10it [00:00, 12.44it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.48it/s]\u001b[A\n",
      "3it [00:00,  9.32it/s]\u001b[A\n",
      "5it [00:00, 12.37it/s]\u001b[A\n",
      "7it [00:00, 14.27it/s]\u001b[A\n",
      "10it [00:00, 11.33it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  7.25it/s]\u001b[A\n",
      "3it [00:00,  6.09it/s]\u001b[A\n",
      "5it [00:00,  8.98it/s]\u001b[A\n",
      "7it [00:00, 11.25it/s]\u001b[A\n",
      "10it [00:01,  9.27it/s][A\n",
      " 40%|████      | 4/10 [01:18<01:42, 17.09s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 18.08it/s]\u001b[A\n",
      "4it [00:00, 17.49it/s]\u001b[A\n",
      "6it [00:00, 17.57it/s]\u001b[A\n",
      "8it [00:00, 17.28it/s]\u001b[A\n",
      "10it [00:00, 13.15it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.99it/s]\u001b[A\n",
      "4it [00:00,  8.39it/s]\u001b[A\n",
      "6it [00:00, 11.38it/s]\u001b[A\n",
      "8it [00:00, 13.61it/s]\u001b[A\n",
      "10it [00:01,  8.81it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.88it/s]\u001b[A\n",
      "4it [00:00, 19.50it/s]\u001b[A\n",
      "7it [00:00, 19.48it/s]\u001b[A\n",
      "10it [00:00, 14.03it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.28it/s]\u001b[A\n",
      "6it [00:00, 20.54it/s]\u001b[A\n",
      "10it [00:00, 15.51it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  3.58it/s]\u001b[A\n",
      "3it [00:00,  8.22it/s]\u001b[A\n",
      "5it [00:00,  9.69it/s]\u001b[A\n",
      "7it [00:00,  9.98it/s]\u001b[A\n",
      "9it [00:01,  8.41it/s]\u001b[A\n",
      "10it [00:01,  6.54it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 15.18it/s]\u001b[A\n",
      "4it [00:00, 15.84it/s]\u001b[A\n",
      "6it [00:01,  4.22it/s]\u001b[A\n",
      "8it [00:01,  4.99it/s]\u001b[A\n",
      "10it [00:01,  5.82it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.48it/s]\u001b[A\n",
      "4it [00:00, 18.89it/s]\u001b[A\n",
      "6it [00:00, 19.22it/s]\u001b[A\n",
      "8it [00:00, 19.00it/s]\u001b[A\n",
      "10it [00:00, 14.72it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.98it/s]\u001b[A\n",
      "4it [00:00, 17.18it/s]\u001b[A\n",
      "6it [00:00, 17.70it/s]\u001b[A\n",
      "8it [00:00, 17.53it/s]\u001b[A\n",
      "10it [00:00, 13.88it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 12.00it/s]\u001b[A\n",
      "4it [00:00, 14.53it/s]\u001b[A\n",
      "6it [00:00, 12.16it/s]\u001b[A\n",
      "8it [00:00, 10.76it/s]\u001b[A\n",
      "10it [00:01,  8.21it/s]\u001b[A\n",
      " 50%|█████     | 5/10 [01:27<01:11, 14.23s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.02it/s]\u001b[A\n",
      "4it [00:00, 16.83it/s]\u001b[A\n",
      "6it [00:00, 15.26it/s]\u001b[A\n",
      "8it [00:00, 16.20it/s]\u001b[A\n",
      "10it [00:00, 16.24it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  4.12it/s]\u001b[A\n",
      "2it [00:00,  4.41it/s]\u001b[A\n",
      "4it [00:00,  6.64it/s]\u001b[A\n",
      "5it [00:00,  5.74it/s]\u001b[A\n",
      "7it [00:01,  5.46it/s]\u001b[A\n",
      "8it [00:01,  5.27it/s]\u001b[A\n",
      "10it [00:01,  5.45it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 16.84it/s]\u001b[A\n",
      "4it [00:00, 17.39it/s]\u001b[A\n",
      "6it [00:00, 15.91it/s]\u001b[A\n",
      "10it [00:00, 17.41it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.16it/s]\u001b[A\n",
      "4it [00:00, 19.45it/s]\u001b[A\n",
      "6it [00:00, 17.74it/s]\u001b[A\n",
      "10it [00:00, 19.15it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 18.34it/s]\u001b[A\n",
      "4it [00:00, 17.19it/s]\u001b[A\n",
      "6it [00:00, 14.16it/s]\u001b[A\n",
      "8it [00:00, 14.34it/s]\u001b[A\n",
      "10it [00:00, 14.68it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 13.75it/s]\u001b[A\n",
      "4it [00:00, 14.74it/s]\u001b[A\n",
      "6it [00:00, 14.09it/s]\u001b[A\n",
      "8it [00:00, 15.18it/s]\u001b[A\n",
      "10it [00:00, 15.03it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.72it/s]\u001b[A\n",
      "4it [00:00, 17.36it/s]\u001b[A\n",
      "6it [00:00, 15.94it/s]\u001b[A\n",
      "10it [00:00, 17.43it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.42it/s]\u001b[A\n",
      "4it [00:00, 18.83it/s]\u001b[A\n",
      "6it [00:00, 16.99it/s]\u001b[A\n",
      "10it [00:00, 18.23it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  2.30it/s]\u001b[A\n",
      "3it [00:00,  6.67it/s]\u001b[A\n",
      "5it [00:00, 10.10it/s]\u001b[A\n",
      "7it [00:01,  5.04it/s]\u001b[A\n",
      "10it [00:01,  6.88it/s][A\n",
      " 60%|██████    | 6/10 [01:34<00:47, 11.95s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.39it/s]\u001b[A\n",
      "6it [00:00, 21.07it/s]\u001b[A\n",
      "10it [00:00, 21.21it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  5.08it/s]\u001b[A\n",
      "3it [00:00,  5.63it/s]\u001b[A\n",
      "6it [00:00, 10.32it/s]\u001b[A\n",
      "10it [00:01,  9.66it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.63it/s]\u001b[A\n",
      "6it [00:00, 19.92it/s]\u001b[A\n",
      "8it [00:00, 19.94it/s]\u001b[A\n",
      "10it [00:00, 19.34it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.43it/s]\u001b[A\n",
      "4it [00:00, 17.62it/s]\u001b[A\n",
      "6it [00:00, 17.72it/s]\u001b[A\n",
      "8it [00:00, 18.06it/s]\u001b[A\n",
      "10it [00:00, 17.95it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  2.30it/s]\u001b[A\n",
      "2it [00:00,  3.06it/s]\u001b[A\n",
      "4it [00:00,  5.48it/s]\u001b[A\n",
      "5it [00:01,  4.46it/s]\u001b[A\n",
      "7it [00:01,  5.39it/s]\u001b[A\n",
      "8it [00:01,  5.76it/s]\u001b[A\n",
      "10it [00:01,  5.71it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 14.30it/s]\u001b[A\n",
      "4it [00:00, 13.91it/s]\u001b[A\n",
      "6it [00:00, 14.23it/s]\u001b[A\n",
      "8it [00:00, 14.54it/s]\u001b[A\n",
      "10it [00:00, 14.36it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.93it/s]\u001b[A\n",
      "6it [00:00, 18.84it/s]\u001b[A\n",
      "10it [00:00, 19.86it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.96it/s]\u001b[A\n",
      "6it [00:00, 21.08it/s]\u001b[A\n",
      "10it [00:00, 21.53it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.58it/s]\u001b[A\n",
      "6it [00:00, 20.91it/s]\u001b[A\n",
      "10it [00:00, 20.12it/s][A\n",
      " 70%|███████   | 7/10 [01:41<00:30, 10.18s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.03it/s]\u001b[A\n",
      "5it [00:00, 19.39it/s]\u001b[A\n",
      "7it [00:00, 17.27it/s]\u001b[A\n",
      "10it [00:00, 17.36it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  3.10it/s]\u001b[A\n",
      "4it [00:00,  7.06it/s]\u001b[A\n",
      "6it [00:00,  7.89it/s]\u001b[A\n",
      "8it [00:01,  8.78it/s]\u001b[A\n",
      "10it [00:01,  6.66it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 17.85it/s]\u001b[A\n",
      "5it [00:00, 19.42it/s]\u001b[A\n",
      "7it [00:00, 17.94it/s]\u001b[A\n",
      "10it [00:00, 17.72it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.61it/s]\u001b[A\n",
      "5it [00:00, 20.72it/s]\u001b[A\n",
      "8it [00:00, 19.26it/s]\u001b[A\n",
      "10it [00:00, 17.89it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  8.56it/s]\u001b[A\n",
      "2it [00:00,  5.65it/s]\u001b[A\n",
      "4it [00:00,  6.25it/s]\u001b[A\n",
      "6it [00:00,  8.45it/s]\u001b[A\n",
      "8it [00:00, 10.12it/s]\u001b[A\n",
      "10it [00:03,  2.71it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 15.77it/s]\u001b[A\n",
      "4it [00:00,  6.55it/s]\u001b[A\n",
      "6it [00:00,  9.01it/s]\u001b[A\n",
      "8it [00:00, 10.82it/s]\u001b[A\n",
      "10it [00:00, 10.55it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.69it/s]\u001b[A\n",
      "5it [00:00, 20.70it/s]\u001b[A\n",
      "8it [00:00, 19.24it/s]\u001b[A\n",
      "10it [00:00, 18.42it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 19.81it/s]\u001b[A\n",
      "5it [00:00, 20.69it/s]\u001b[A\n",
      "8it [00:00, 19.28it/s]\u001b[A\n",
      "10it [00:00, 18.73it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  3.93it/s]\u001b[A\n",
      "4it [00:00, 11.69it/s]\u001b[A\n",
      "6it [00:00, 11.19it/s]\u001b[A\n",
      "8it [00:00, 12.95it/s]\u001b[A\n",
      "10it [00:00, 11.35it/s]\u001b[A\n",
      " 80%|████████  | 8/10 [01:51<00:20, 10.07s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.67it/s]\u001b[A\n",
      "6it [00:00, 18.75it/s]\u001b[A\n",
      "8it [00:00, 19.16it/s]\u001b[A\n",
      "10it [00:00, 17.87it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00,  5.16it/s]\u001b[A\n",
      "4it [00:00,  9.14it/s]\u001b[A\n",
      "6it [00:00,  6.03it/s]\u001b[A\n",
      "8it [00:01,  6.26it/s]\u001b[A\n",
      "10it [00:01,  7.11it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 18.02it/s]\u001b[A\n",
      "4it [00:00, 17.40it/s]\u001b[A\n",
      "6it [00:00, 15.85it/s]\u001b[A\n",
      "8it [00:00, 17.11it/s]\u001b[A\n",
      "10it [00:00, 16.19it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.55it/s]\u001b[A\n",
      "6it [00:00, 18.69it/s]\u001b[A\n",
      "10it [00:00, 18.24it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00,  2.60it/s]\u001b[A\n",
      "4it [00:00,  5.29it/s]\u001b[A\n",
      "6it [00:01,  7.54it/s]\u001b[A\n",
      "8it [00:01,  9.93it/s]\u001b[A\n",
      "10it [00:02,  3.36it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 15.47it/s]\u001b[A\n",
      "4it [00:00, 15.96it/s]\u001b[A\n",
      "6it [00:00, 15.05it/s]\u001b[A\n",
      "8it [00:00, 15.46it/s]\u001b[A\n",
      "10it [00:00, 14.85it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.05it/s]\u001b[A\n",
      "6it [00:00, 18.96it/s]\u001b[A\n",
      "10it [00:00, 18.17it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.57it/s]\u001b[A\n",
      "6it [00:00, 19.33it/s]\u001b[A\n",
      "10it [00:00, 18.50it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 20.63it/s]\u001b[A\n",
      "6it [00:00, 18.98it/s]\u001b[A\n",
      "10it [00:07,  1.33it/s][A\n",
      " 90%|█████████ | 9/10 [02:06<00:11, 11.75s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 13.37it/s]\u001b[A\n",
      "5it [00:00, 16.95it/s]\u001b[A\n",
      "7it [00:00, 17.73it/s]\u001b[A\n",
      "10it [00:00, 10.54it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:07,  7.40s/it]\u001b[A\n",
      "4it [00:07,  1.44s/it]\u001b[A\n",
      "6it [00:07,  1.20it/s]\u001b[A\n",
      "8it [00:07,  1.80it/s]\u001b[A\n",
      "10it [00:08,  1.17it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.58it/s]\u001b[A\n",
      "4it [00:00, 16.88it/s]\u001b[A\n",
      "6it [00:00, 16.63it/s]\u001b[A\n",
      "8it [00:00, 17.19it/s]\u001b[A\n",
      "10it [00:01,  9.98it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 13.64it/s]\u001b[A\n",
      "4it [00:00, 15.86it/s]\u001b[A\n",
      "6it [00:00, 15.79it/s]\u001b[A\n",
      "8it [00:00, 16.42it/s]\u001b[A\n",
      "10it [00:00, 11.02it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:08,  8.56s/it]\u001b[A\n",
      "2it [00:08,  3.63s/it]\u001b[A\n",
      "4it [00:08,  1.40s/it]\u001b[A\n",
      "5it [00:10,  1.33s/it]\u001b[A\n",
      "7it [00:11,  1.04it/s]\u001b[A\n",
      "10it [00:19,  1.94s/it][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:07,  7.23s/it]\u001b[A\n",
      "2it [00:07,  3.32s/it]\u001b[A\n",
      "4it [00:07,  1.27s/it]\u001b[A\n",
      "6it [00:08,  1.42it/s]\u001b[A\n",
      "8it [00:08,  2.24it/s]\u001b[A\n",
      "10it [00:15,  1.53s/it]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.11it/s]\u001b[A\n",
      "3it [00:00, 14.32it/s]\u001b[A\n",
      "5it [00:00, 15.36it/s]\u001b[A\n",
      "7it [00:00, 15.81it/s]\u001b[A\n",
      "10it [00:00, 10.04it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  9.71it/s]\u001b[A\n",
      "3it [00:00, 15.47it/s]\u001b[A\n",
      "5it [00:00, 16.44it/s]\u001b[A\n",
      "7it [00:00, 16.91it/s]\u001b[A\n",
      "10it [00:00, 11.44it/s][A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:08,  8.57s/it]\u001b[A\n",
      "3it [00:08,  2.26s/it]\u001b[A\n",
      "5it [00:08,  1.13s/it]\u001b[A\n",
      "7it [00:09,  1.38it/s]\u001b[A\n",
      "10it [00:17,  1.74s/it][A\n",
      "100%|██████████| 10/10 [03:11<00:00, 19.19s/it]\n"
     ]
    }
   ],
   "source": [
    "zeroshot_classifers = []\n",
    "for i in tqdm(range(10)):\n",
    "    sample = pd.concat([eval_df[eval_df[\"toxic\"] == 1].sample(5), eval_df[eval_df[\"toxic\"] == 0].sample(5)])\n",
    "    zsclassifiers = []\n",
    "    zs_f1_scores = []\n",
    "    for i in range(1, 10):\n",
    "        prompt_classifier = ZeroShotClassifier(eval(\"prompt\" + str(i)), eval(\"verbalizer\" + str(i)), tokenizer, model)\n",
    "        zsclassifiers.append(prompt_classifier)\n",
    "        _, score = prompt_classifier.evaluate(sample)\n",
    "        zs_f1_scores.append(score)\n",
    "    zeroshot_classifers.append(np.argmax(zs_f1_scores))\n",
    "zeroshot_model_idx = max(set(zeroshot_classifers), key=zeroshot_classifers.count)\n",
    "zeroshot_model = zsclassifiers[zeroshot_model_idx]\n",
    "#sel_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4444444444444445,\n",
       " 0.6153846153846154,\n",
       " 0.7142857142857143,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs_f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_prompt_classifier = ZeroShotClassifier(prompt7, verbalizer7, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ZeroShotClassifier at 0x145f31b998e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs_prompt_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ZeroShotClassifier"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(zs_prompt_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\nIf your server said this, how much would you like to tip them between 0 and 20%:\\n\\n{}\\n\\nType a number between 0 and 20 that you will tip him.\\n',\n",
       " <__main__.ZeroShotClassifier at 0x14603d8a2bb0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_model.template, zeroshot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjdGG9SIrbmH"
   },
   "source": [
    "## Problem 4. \n",
    "(10 points) For comparison with prompt-based learning models, train a regular classifier using Trainer and the MiniLM parameters on all the training data (very similar to what you did in Homework 3!). You should train your model for at least two epochs, but you’re not required to do any hyperparameter tuning (you just need a score). Predict the toxicity of the provided test data and calculate the F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkmETxCGrZ-8"
   },
   "source": [
    "## **Regular Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ropu5eg4Zc1I",
    "outputId": "879e113b-69ba-462b-e62d-d293326cd781"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXazLBaGZgf0",
    "outputId": "22ac8f2e-202a-4f0b-edcc-747d4aba2f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fnEkMrNuZi5Z",
    "outputId": "3d7d2acf-37e1-42ef-d5b2-f1df8c9c2822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify there's at least one GPU sitting around (or not if you want to try CPU!)\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorWithPadding, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformatting train and evaluation dataframes\n",
    "# train_df = train_df.drop(\"id\", axis=1)\n",
    "# eval_df = eval_df.drop(\"id\", axis=1)\n",
    "train_df[\"toxic\"] = train_df[\"toxic\"].astype(int)\n",
    "eval_df[\"toxic\"] = eval_df[\"toxic\"].astype(int)\n",
    "# Testing data\n",
    "# test_df = test_df.drop(\"id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Dataset.from_pandas(train_df)\n",
    "# eval_dataset = Dataset.from_pandas(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBkc7Fe8tSGR"
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "# tokenizer_miniLM = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "\n",
    "# def preprocess_function(data):\n",
    "#     return tokenizer_miniLM(data['comment_text'], padding=True, truncation=True, max_length=128)\n",
    "\n",
    "# # tokenized_X_train = preprocess_function(list(train_df['comment_text']))\n",
    "# # tokenized_X_eval = preprocess_function(list(eval_df['comment_text']))\n",
    "\n",
    "# tokenized_X_train = train_dataset.map(preprocess_function, batched=True)\n",
    "# tokenized_X_eval = eval_dataset.map(preprocess_function, batched=True)\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer_miniLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9tFQYLjtUAH"
   },
   "outputs": [],
   "source": [
    "# # Define a Class to prepare the dataset in desired format to feed in Trainer class\n",
    "# class DataProcess(torch.utils.data.Dataset):\n",
    "#     def __init__(self, encodings, labels = None):\n",
    "#         self.encodings = encodings\n",
    "#         self.labels = labels\n",
    "  \n",
    "#     def __getitem__(self, idx):\n",
    "#         item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "#         if self.labels:\n",
    "#             item[\"toxic\"] = torch.tensor(self.labels[idx])\n",
    "#         return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = DataProcess(tokenized_X_train, list(train_df['toxic']))\n",
    "# eval_dataset = DataProcess(tokenized_X_eval, list(eval_df['toxic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwZWzypbtYJE"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error, f1_score\n",
    "\n",
    "# import torch\n",
    "# # from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "# # tokenizer = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "# # model = AutoModelForSequenceClassification.from_pretrained('microsoft/MiniLM-L12-H384-uncased', num_labels=2)\n",
    "\n",
    "# def compute_metrics(pred):\n",
    "#     scores = pred.label_ids\n",
    "#     prediction = pred.predictions.squeeze()\n",
    "#     return {\"rmse\": np.sqrt(mean_squared_error(scores, prediction))}\n",
    "\n",
    "# # model_name = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "# output_dir = '.'\n",
    "\n",
    "# def model_init():\n",
    "#     #tokenizer = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "#     miniLMmodel = AutoModelForSequenceClassification.from_pretrained('microsoft/MiniLM-L12-H384-uncased', num_labels=2)\n",
    "#     model = miniLMmodel.to(device)\n",
    "\n",
    "#     return model #AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "     \n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=output_dir,\n",
    "#     evaluation_strategy='epoch',     # evaluate after each epoch\n",
    "#     save_strategy='epoch',           # save after each epoch\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=2,\n",
    "#     weight_decay=0.01,\n",
    "#     do_eval=True,\n",
    "#     seed=1234,\n",
    "#     push_to_hub=False,\n",
    "#     logging_dir=output_dir + 'logs/',\n",
    "#     logging_steps=10,\n",
    "#     load_best_model_at_end=True,\n",
    "#     #metric_for_best_model='accuracy',\n",
    "#     metric_for_best_model=\"f1\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "tokenized_X_train = preprocess_function(list(train_df['comment_text']))\n",
    "tokenized_X_eval = preprocess_function(list(eval_df['comment_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Class to prepare the dataset in desired format to feed in Trainer class\n",
    "class DataProcess(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels = None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataProcess(tokenized_X_train, list(train_df['toxic']))\n",
    "eval_dataset = DataProcess(tokenized_X_eval, list(eval_df['toxic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTR18EyDtWlq"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "# tokenizer = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('microsoft/MiniLM-L12-H384-uncased', num_labels=2)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    scores = pred.label_ids\n",
    "    prediction = pred.predictions.squeeze()\n",
    "    return {\"rmse\": np.sqrt(mean_squared_error(scores, prediction))}\n",
    "\n",
    "# model_name = \"microsoft/MiniLM-L12-H384-uncased\"\n",
    "output_dir = '.'\n",
    "\n",
    "def model_init():\n",
    "    #tokenizer = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "    miniLMmodel = AutoModelForSequenceClassification.from_pretrained('microsoft/MiniLM-L12-H384-uncased', num_labels=2)\n",
    "    model = miniLMmodel.to(device)\n",
    "\n",
    "    return model\n",
    "     \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy='epoch',     # evaluate after each epoch\n",
    "    save_strategy='epoch',           # save after each epoch\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    do_eval=True,\n",
    "    push_to_hub=False,\n",
    "    logging_dir=output_dir + 'logs/',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    #metric_for_best_model='accuracy',\n",
    "    metric_for_best_model=\"rmse\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/clairewo/.cache/huggingface/hub/models--microsoft--MiniLM-L12-H384-uncased/snapshots/44acabbec0ef496f6dbc93adadea57f376b7c0ec/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/MiniLM-L12-H384-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/clairewo/.cache/huggingface/hub/models--microsoft--MiniLM-L12-H384-uncased/snapshots/44acabbec0ef496f6dbc93adadea57f376b7c0ec/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,    \n",
    "    args=training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,    \n",
    "    compute_metrics = compute_metrics, # compute_metrics=lambda pred: {'accuracy': (pred.predictions.argmax(-1) == pred.label_ids).mean()},\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mBWfzwg_cxjw",
    "outputId": "e6b3d110-e5a3-4044-aa6a-fcdf17c13442"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/clairewo/.cache/huggingface/hub/models--microsoft--MiniLM-L12-H384-uncased/snapshots/44acabbec0ef496f6dbc93adadea57f376b7c0ec/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/MiniLM-L12-H384-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/clairewo/.cache/huggingface/hub/models--microsoft--MiniLM-L12-H384-uncased/snapshots/44acabbec0ef496f6dbc93adadea57f376b7c0ec/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/clairewo/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 159571\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 29922\n",
      "  Number of trainable parameters = 33360770\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclairewo\u001b[0m (\u001b[33mclairewoo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/clairewo/si630_hw/wandb/run-20230425_193134-q9sam4ss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/clairewoo/huggingface/runs/q9sam4ss\" target=\"_blank\">.</a></strong> to <a href=\"https://wandb.ai/clairewoo/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2323037/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m         )\n\u001b[0;32m-> 1501\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1502\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1747\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m                 if (\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2507\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2508\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2538\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2539\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2540\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2541\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2542\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1553\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 )\n\u001b[1;32m    602\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 419\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    420\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mmixed_query_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# If this is instantiated as a cross-attention module, the keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRhK7qlHlPre",
    "outputId": "8479cb0b-7534-4dae-c084-ec48d31855cc"
   },
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# import random\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"SI630-HW4-miniLM-regular-classifier\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 10,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # simulate training\n",
    "# epochs = 10\n",
    "# offset = random.random() / 5\n",
    "# for epoch in range(2, epochs):\n",
    "#     acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "#     loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "    \n",
    "#     # log metrics to wandb\n",
    "#     wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "    \n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFAo63-Lrj3K"
   },
   "source": [
    "## **Comparison and Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VI3K8zaArl60"
   },
   "source": [
    "## Problem 5. \n",
    "(20 points) Using your patterns and verbalizers, train separate prompt-based learning models on 10, 50, 100, and 500 instances of data. Your data should be randomly sampled from the training data but be sure to have examples of each class. You are free to choose which instances you use and what distribution of toxic/non-toxic labels are in your training data (provided you have at least one example of each). For each model, predict the scores for the provided development data and calculate the Binary F1 (toxic is the positive class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159494</th>\n",
       "      <td>\"\\n\\n our previous conversation \\n\\nyou fuckin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159514</th>\n",
       "      <td>YOU ARE A MISCHIEVIOUS PUBIC HAIR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159541</th>\n",
       "      <td>Your absurd edits \\n\\nYour absurd edits on gre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159546</th>\n",
       "      <td>\"\\n\\nHey listen don't you ever!!!! Delete my e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159554</th>\n",
       "      <td>and i'm going to keep posting the stuff u dele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic\n",
       "6            COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "12      Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "16      Bye! \\n\\nDon't look, come or think of comming ...      1\n",
       "42      You are gay or antisemmitian? \\n\\nArchangel WH...      1\n",
       "43               FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1\n",
       "...                                                   ...    ...\n",
       "159494  \"\\n\\n our previous conversation \\n\\nyou fuckin...      1\n",
       "159514                  YOU ARE A MISCHIEVIOUS PUBIC HAIR      1\n",
       "159541  Your absurd edits \\n\\nYour absurd edits on gre...      1\n",
       "159546  \"\\n\\nHey listen don't you ever!!!! Delete my e...      1\n",
       "159554  and i'm going to keep posting the stuff u dele...      1\n",
       "\n",
       "[15294 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"toxic\"]== 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "dATNqCnirlYO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77989</th>\n",
       "      <td>yes, and lets also delete or change any articl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154931</th>\n",
       "      <td>Do you want me to ban you? I am prejudice agai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142348</th>\n",
       "      <td>FUCK YOU!!!!=\\n   FUCK YOU, YOU STUPID BASTARD...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119011</th>\n",
       "      <td>Rats at the Wikipedia web site \\n\\nRats are ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33268</th>\n",
       "      <td>He hadn't been in the USA since Bill Clinton w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142266</th>\n",
       "      <td>The thing to remember is I and a lot of others...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119065</th>\n",
       "      <td>I suggest you pick out the specific claims in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58736</th>\n",
       "      <td>January 2009 \\n\\nFine then. I'll stop.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40156</th>\n",
       "      <td>Despite my last comment, you kept on edit-warr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48024</th>\n",
       "      <td>There are several derogatory remarks made here...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic\n",
       "77989   yes, and lets also delete or change any articl...      1\n",
       "154931  Do you want me to ban you? I am prejudice agai...      1\n",
       "142348  FUCK YOU!!!!=\\n   FUCK YOU, YOU STUPID BASTARD...      1\n",
       "119011  Rats at the Wikipedia web site \\n\\nRats are ar...      1\n",
       "33268   He hadn't been in the USA since Bill Clinton w...      1\n",
       "142266  The thing to remember is I and a lot of others...      0\n",
       "119065  I suggest you pick out the specific claims in ...      0\n",
       "58736              January 2009 \\n\\nFine then. I'll stop.      0\n",
       "40156   Despite my last comment, you kept on edit-warr...      0\n",
       "48024   There are several derogatory remarks made here...      0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10_1 = train_df[train_df[\"toxic\"]== 1].sample(n=5) # toxic\n",
    "df_10_2 = train_df[train_df[\"toxic\"]== 0].sample(n=5) # nontoxic\n",
    "\n",
    "df_10 = pd.concat([df_10_1, df_10_2])\n",
    "df_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46361</th>\n",
       "      <td>What the fuck are you talking about?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38512</th>\n",
       "      <td>Let's get to fuckin big daddy ==\\nMan I love s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109209</th>\n",
       "      <td>\"\\n\\nWhat right do you have to block the White...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44369</th>\n",
       "      <td>fuck u i will do as i please</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88341</th>\n",
       "      <td>Remove \\n\\nNeilN needs to extract his head fro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic\n",
       "46361                What the fuck are you talking about?      1\n",
       "38512   Let's get to fuckin big daddy ==\\nMan I love s...      1\n",
       "109209  \"\\n\\nWhat right do you have to block the White...      1\n",
       "44369                        fuck u i will do as i please      1\n",
       "88341   Remove \\n\\nNeilN needs to extract his head fro...      1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_50_1 = train_df[train_df[\"toxic\"]== 1].sample(n=25) # toxic\n",
    "df_50_2 = train_df[train_df[\"toxic\"]== 0].sample(n=25) # nontoxic\n",
    "\n",
    "df_50 = pd.concat([df_50_1, df_50_2])\n",
    "df_50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Hi \\n\\nIm a fucking bitch.\\n\\n50.180.208.181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131453</th>\n",
       "      <td>BEST BEHAVIOUR IS A SINGLE! \\n\\nhttp://www.ndu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36587</th>\n",
       "      <td>be a toilet. so everyone can piss her off. hey...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96561</th>\n",
       "      <td>is all pretty gay if u ask me...bunch or fucki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88927</th>\n",
       "      <td>Hey you! \\n\\nI'll strike you down without a se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic\n",
       "442          Hi \\n\\nIm a fucking bitch.\\n\\n50.180.208.181      1\n",
       "131453  BEST BEHAVIOUR IS A SINGLE! \\n\\nhttp://www.ndu...      1\n",
       "36587   be a toilet. so everyone can piss her off. hey...      1\n",
       "96561   is all pretty gay if u ask me...bunch or fucki...      1\n",
       "88927   Hey you! \\n\\nI'll strike you down without a se...      1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_500_1 = train_df[train_df[\"toxic\"]== 1].sample(n=250) # toxic\n",
    "df_500_2 = train_df[train_df[\"toxic\"]== 0].sample(n=250) # nontoxic\n",
    "\n",
    "df_500 = pd.concat([df_500_1, df_500_2])\n",
    "df_500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swfKmr_8rs-J"
   },
   "source": [
    "## Problem 6. \n",
    "(10 points) Let’s compare our two prompt-based models (the few-shot and zero-shot) and our regular all-data MiniLM model. Plot the score for each prompt-based learning model and your full-data MiniLM model using Seaborn. Use the training data size as the x-axis and Binary F1 as the y-axis. For the zero-shot models, you can draw these as different horizontal lines or points (since they don’t have training data amounts) If you are feeling curious, feel free to train regular models on different sizes/distributions of data and include those too. Write your guess on how many instances you think you need to train a prompt-based learning model that will reach the performance of a MiniLM model trained on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G1DzTMlQryZ3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6LstF_Lr1Up"
   },
   "source": [
    "## Problem 7. \n",
    "(10 points) How good can we get our zero-shot model? Pick your favorite zero-shot prompt and predict the labels for the provided test data. Upload these predictions to the Kaggle competition posted about on Piazza. Scores within some reasonable range (e.g., not zero or near-zero) will receive full credit, though aim high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer_pred = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "NLn4nTgxr4yF"
   },
   "outputs": [],
   "source": [
    "zs_prompt_classifier = ZeroShotClassifier(prompt6, verbalizer6, tokenizer_pred, model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ZeroShotClassifier at 0x145f30fafbb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zs_prompt_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenizer = AutoTokenizer.from_pretrained('microsoft/MiniLM-L12-H384-uncased')\n",
    "\n",
    "# def preprocess_function_pred(data):\n",
    "#     return tokenizer_pred(data, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# tokenized_X_test = preprocess_function_pred(list(test_df['comment_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = DataProcess(tokenized_X_test) \n",
    "# test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# zeroshot_model.evaluate(test_df, eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv(\"jigsaw-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d9836e25d089cab8</td>\n",
       "      <td>I suggest you add this to the LARPA wiki inste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3fbed19498484f71</td>\n",
       "      <td>, 19 May 2008 (UTC) \\n ::The AFD is truly sad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>be887f0617e43898</td>\n",
       "      <td>===Train name, misnomer=== \\n The problem is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ddb1781c5174e079</td>\n",
       "      <td>March 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f04966e1d4d2b61</td>\n",
       "      <td>unfair warnings as threats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32004</th>\n",
       "      <td>22abb35000de7828</td>\n",
       "      <td>== Motion Picture Association of America film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32005</th>\n",
       "      <td>834fd790ecbcf68f</td>\n",
       "      <td>\" \\n\\n ==WikiProject Pharmacology Update== \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32006</th>\n",
       "      <td>76417c0f552a71b2</td>\n",
       "      <td>That's nonsense. Most lists of Jews explicitly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32007</th>\n",
       "      <td>6c7c337a97b1d905</td>\n",
       "      <td>==References== \\n Removed Youtube link to V-En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32008</th>\n",
       "      <td>b287221057d59bb9</td>\n",
       "      <td>\" \\n ::Yeah, I know the research is still ongo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                       comment_text\n",
       "0      d9836e25d089cab8  I suggest you add this to the LARPA wiki inste...\n",
       "1      3fbed19498484f71  , 19 May 2008 (UTC) \\n ::The AFD is truly sad ...\n",
       "2      be887f0617e43898  ===Train name, misnomer=== \\n The problem is t...\n",
       "3      ddb1781c5174e079                                         March 2006\n",
       "4      6f04966e1d4d2b61                         unfair warnings as threats\n",
       "...                 ...                                                ...\n",
       "32004  22abb35000de7828  == Motion Picture Association of America film ...\n",
       "32005  834fd790ecbcf68f  \" \\n\\n ==WikiProject Pharmacology Update== \\n ...\n",
       "32006  76417c0f552a71b2  That's nonsense. Most lists of Jews explicitly...\n",
       "32007  6c7c337a97b1d905  ==References== \\n Removed Youtube link to V-En...\n",
       "32008  b287221057d59bb9  \" \\n ::Yeah, I know the research is still ongo...\n",
       "\n",
       "[32009 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32009it [2:11:21,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "zs_preds = zeroshot_model.evaluate(test_df, eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroshot_predictions = np.array(zs_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32009"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zs_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"toxic\"] = zeroshot_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"sample_jigsaw-submission_clairewo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df = test_df.drop(columns = [\"comment_text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_df.to_csv(\"clairewo_jigsaw-submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv(\"clairewo_jigsaw-submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d9836e25d089cab8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3fbed19498484f71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>be887f0617e43898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ddb1781c5174e079</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f04966e1d4d2b61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32004</th>\n",
       "      <td>22abb35000de7828</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32005</th>\n",
       "      <td>834fd790ecbcf68f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32006</th>\n",
       "      <td>76417c0f552a71b2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32007</th>\n",
       "      <td>6c7c337a97b1d905</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32008</th>\n",
       "      <td>b287221057d59bb9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  toxic\n",
       "0      d9836e25d089cab8      0\n",
       "1      3fbed19498484f71      1\n",
       "2      be887f0617e43898      1\n",
       "3      ddb1781c5174e079      1\n",
       "4      6f04966e1d4d2b61      1\n",
       "...                 ...    ...\n",
       "32004  22abb35000de7828      1\n",
       "32005  834fd790ecbcf68f      1\n",
       "32006  76417c0f552a71b2      1\n",
       "32007  6c7c337a97b1d905      0\n",
       "32008  b287221057d59bb9      1\n",
       "\n",
       "[32009 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08759c824b4d4afc89b0fd78f0dc42d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f0f275a6f4c470fa3cbbcd9026c02a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ff09cf8e5224831acb6cf998f3e2152": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e4cf7581614df8ac264a96bb8218be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f6510ab907d4daa9a10fac9b1a5fa2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08759c824b4d4afc89b0fd78f0dc42d4",
      "placeholder": "​",
      "style": "IPY_MODEL_34e4cf7581614df8ac264a96bb8218be",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "4f74c926b64741348e49ec2456ee3106": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bb9b1c9e34f413988ba159717228559": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62f242c6292d4b3c9be53ddcd06571dd",
      "placeholder": "​",
      "style": "IPY_MODEL_1f0f275a6f4c470fa3cbbcd9026c02a0",
      "value": " 133M/133M [00:01&lt;00:00, 91.2MB/s]"
     }
    },
    "62f242c6292d4b3c9be53ddcd06571dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c1bb4a291a847f8861e2542df0c9af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f74c926b64741348e49ec2456ee3106",
      "max": 133483028,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f3feccdf6f040a29429678b7595d18a",
      "value": 133483028
     }
    },
    "9f3feccdf6f040a29429678b7595d18a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a85ca4d7bab44eec9fe2881b71ae2177": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f6510ab907d4daa9a10fac9b1a5fa2a",
       "IPY_MODEL_7c1bb4a291a847f8861e2542df0c9af9",
       "IPY_MODEL_5bb9b1c9e34f413988ba159717228559"
      ],
      "layout": "IPY_MODEL_1ff09cf8e5224831acb6cf998f3e2152"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
